# app/services/prompts/life_prompts.py
import os
import asyncio
from typing import List, Dict, Tuple, Optional
from ..openai_service import OpenAIService
from ..minimax_service import MinimaxService

class LifePromptsService:
    def __init__(self):
        self.openai_service = OpenAIService()
        self.minimax_service = MinimaxService()
    
    async def execute_complete_workflow(self, image_path: str, description: str, num_steps: int = 5) -> Dict:
        """
        ì™„ì „í•œ 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        
        1. OpenAI Vision APIë¡œ ì‚¬ì§„+ì„¤ëª… â†’ ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        2. Minimax APIë¡œ ì‚¬ì§„+í”„ë¡¬í”„íŠ¸ë“¤ â†’ ì´ë¯¸ì§€ë“¤ ìƒì„±
        3. OpenAI Vision APIë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ ë¶„ì„ â†’ ìµœì  ì´ë¯¸ì§€ ì„ íƒ + ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ìƒì„±
        4. Minimax APIë¡œ ì„ íƒëœ ì´ë¯¸ì§€+ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ â†’ ë¹„ë””ì˜¤ ìƒì„±
        
        Args:
            image_path: ì—…ë¡œë“œëœ ê°•ì•„ì§€ ì‚¬ì§„ ê²½ë¡œ
            description: ì‚¬ìš©ì ì„¤ëª…
            num_steps: ìƒì„±í•  ë‹¨ê³„ ìˆ˜ (ê¸°ë³¸ 5ê°œ)
            
        Returns:
            ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        
        result = {
            "status": "processing",
            "step": 1,
            "step_prompts": [],
            "generated_images": [],
            "selected_image_index": 0,
            "selection_reason": "",
            "video_prompt": "",
            "final_video_path": None,
            "error": None
        }
        
        try:
            print("=" * 60)
            print("ğŸš€ ìƒˆë¡œìš´ 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
            print("=" * 60)
            
            # 1ë‹¨ê³„: ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
            print("ğŸ“ 1ë‹¨ê³„: ì‚¬ì§„ê³¼ ì„¤ëª…ìœ¼ë¡œ ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            step_prompts = await self.openai_service.generate_step_prompts_from_image_and_description(
                image_path, description, num_steps
            )
            
            if not step_prompts:
                raise Exception("1ë‹¨ê³„ ì‹¤íŒ¨: ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨")
                
            result["step_prompts"] = step_prompts
            result["step"] = 2
            print(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ: {len(step_prompts)}ê°œ í”„ë¡¬í”„íŠ¸ ìƒì„±")
            for i, prompt in enumerate(step_prompts):
                print(f"   {i+1}. {prompt}")
            
            # 2ë‹¨ê³„: ì´ë¯¸ì§€ ìƒì„±
            print("\nğŸ¨ 2ë‹¨ê³„: ì°¸ê³  ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸ë“¤ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
            generated_images = await self.minimax_service.generate_images_from_prompts_and_reference(
                step_prompts, image_path
            )
            
            if not generated_images:
                raise Exception("2ë‹¨ê³„ ì‹¤íŒ¨: ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
                
            result["generated_images"] = generated_images
            result["step"] = 3
            print(f"âœ… 2ë‹¨ê³„ ì™„ë£Œ: {len(generated_images)}ê°œ ì´ë¯¸ì§€ ìƒì„±")
            
            # 3ë‹¨ê³„: ìµœì  ì´ë¯¸ì§€ ì„ íƒ ë° ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ìƒì„±
            print("\nğŸ” 3ë‹¨ê³„: OpenAIë¡œ ìµœì  ì´ë¯¸ì§€ ì„ íƒ ë° ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            selected_index, selection_reason, video_prompt = await self.openai_service.select_best_image_and_create_video_prompt(
                generated_images, step_prompts, description, image_path
            )
            
            result["selected_image_index"] = selected_index
            result["selection_reason"] = selection_reason
            result["video_prompt"] = video_prompt
            result["step"] = 4
            print(f"âœ… 3ë‹¨ê³„ ì™„ë£Œ:")
            print(f"   ì„ íƒëœ ì´ë¯¸ì§€: {selected_index + 1}ë²ˆ ({os.path.basename(generated_images[selected_index])})")
            print(f"   ì„ íƒ ì´ìœ : {selection_reason}")
            print(f"   ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸: {video_prompt}")
            
            # 4ë‹¨ê³„: ë¹„ë””ì˜¤ ìƒì„±
            print("\nğŸ¬ 4ë‹¨ê³„: ì„ íƒëœ ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸ë¡œ ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")
            selected_image_path = generated_images[selected_index]
            final_video_path = await self.minimax_service.generate_video_from_image_and_prompt(
                selected_image_path, video_prompt
            )
            
            if not final_video_path:
                raise Exception("4ë‹¨ê³„ ì‹¤íŒ¨: ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")
                
            result["final_video_path"] = final_video_path
            result["status"] = "completed"
            result["step"] = 5
            
            print("=" * 60)
            print("ğŸ‰ 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")
            print(f"ğŸ“¹ ìµœì¢… ë¹„ë””ì˜¤: {os.path.basename(final_video_path)}")
            print("=" * 60)
            
            return result
            
        except Exception as e:
            print(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤íŒ¨ (ë‹¨ê³„ {result['step']}): {e}")
            result["status"] = "failed"
            result["error"] = str(e)
            return result
    
    async def execute_step_by_step(self, image_path: str, description: str, step: int, previous_data: Optional[Dict] = None, num_steps: int = 5) -> Dict:
        """
        ë‹¨ê³„ë³„ ì‹¤í–‰ (ê°œë³„ ë‹¨ê³„ë³„ë¡œ í˜¸ì¶œ ê°€ëŠ¥)
        
        Args:
            image_path: ì—…ë¡œë“œëœ ê°•ì•„ì§€ ì‚¬ì§„ ê²½ë¡œ
            description: ì‚¬ìš©ì ì„¤ëª…
            step: ì‹¤í–‰í•  ë‹¨ê³„ (1-4)
            previous_data: ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ ë°ì´í„°
            num_steps: ìƒì„±í•  ë‹¨ê³„ ìˆ˜
            
        Returns:
            í•´ë‹¹ ë‹¨ê³„ì˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        
        try:
            if step == 1:
                # 1ë‹¨ê³„: ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
                print(f"ğŸ“ 1ë‹¨ê³„ ì‹¤í–‰: ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„± ({num_steps}ê°œ)")
                step_prompts = await self.openai_service.generate_step_prompts_from_image_and_description(
                    image_path, description, num_steps
                )
                
                return {
                    "status": "success",
                    "step": 1,
                    "data": {
                        "step_prompts": step_prompts,
                        "count": len(step_prompts)
                    }
                }
                
            elif step == 2:
                # 2ë‹¨ê³„: ì´ë¯¸ì§€ ìƒì„±
                if not previous_data or "step_prompts" not in previous_data:
                    return {"status": "error", "message": "1ë‹¨ê³„ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}
                
                print(f"ğŸ¨ 2ë‹¨ê³„ ì‹¤í–‰: ì´ë¯¸ì§€ ìƒì„± ({len(previous_data['step_prompts'])}ê°œ)")
                generated_images = await self.minimax_service.generate_images_from_prompts_and_reference(
                    previous_data["step_prompts"], image_path
                )
                
                return {
                    "status": "success",
                    "step": 2,
                    "data": {
                        "generated_images": generated_images,
                        "count": len(generated_images)
                    }
                }
                
            elif step == 3:
                # 3ë‹¨ê³„: ì´ë¯¸ì§€ ì„ íƒ ë° ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ìƒì„±
                if not previous_data or "generated_images" not in previous_data or "step_prompts" not in previous_data:
                    return {"status": "error", "message": "1-2ë‹¨ê³„ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}
                
                print("ğŸ” 3ë‹¨ê³„ ì‹¤í–‰: ìµœì  ì´ë¯¸ì§€ ì„ íƒ ë° ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ìƒì„±")
                selected_index, selection_reason, video_prompt = await self.openai_service.select_best_image_and_create_video_prompt(
                    previous_data["generated_images"], previous_data["step_prompts"], description, image_path
                )
                
                return {
                    "status": "success",
                    "step": 3,
                    "data": {
                        "selected_image_index": selected_index,
                        "selected_image_path": previous_data["generated_images"][selected_index],
                        "selection_reason": selection_reason,
                        "video_prompt": video_prompt
                    }
                }
                
            elif step == 4:
                # 4ë‹¨ê³„: ë¹„ë””ì˜¤ ìƒì„±
                if not previous_data or "selected_image_path" not in previous_data or "video_prompt" not in previous_data:
                    return {"status": "error", "message": "1-3ë‹¨ê³„ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}
                
                print("ğŸ¬ 4ë‹¨ê³„ ì‹¤í–‰: ë¹„ë””ì˜¤ ìƒì„±")
                final_video_path = await self.minimax_service.generate_video_from_image_and_prompt(
                    previous_data["selected_image_path"], previous_data["video_prompt"]
                )
                
                if not final_video_path:
                    return {"status": "error", "message": "ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨"}
                
                return {
                    "status": "success",
                    "step": 4,
                    "data": {
                        "final_video_path": final_video_path
                    }
                }
                
            else:
                return {"status": "error", "message": f"ìœ íš¨í•˜ì§€ ì•Šì€ ë‹¨ê³„: {step} (1-4ë§Œ ê°€ëŠ¥)"}
                
        except Exception as e:
            return {
                "status": "error",
                "step": step,
                "message": str(e)
            } 